# -*- coding: utf-8 -*-
"""RBF_Kernel_Kmeans_Q2_iii_B.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VuLcpoICO9OgOl80GkMCvwEytS0uzXmn

Importing Required Libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.linalg import eigh
from sklearn.preprocessing import normalize

"""Reading the dataset (Assuming the dataset is uploaded in files.)"""

dataset = pd.read_csv("Dataset.csv", names=['p','q']) #datapoint vectors are x1, x2,...xn and each x1 is of type [p,q].T

X_dataset=dataset.to_numpy()  #here the datapoints are in rows Therefore, x1 = [f1, f2] form

def get_rbf_kernel(dataset,sigma):
  N=dataset.shape[0] #number of datapoints
  
  dist_mat=np.zeros((N,N)) #initialising distance matrix

  for i in range(N):

    array=np.sum((X_dataset[i] - dataset)**2,axis=1)
    dist_mat[:,i]=array

  constant=1/(2.0*sigma**2)
  K=np.exp(np.multiply(-1*constant,dist_mat))

  return K

def rbf_kernel_kmeans(K,num_clusters):
    
  e_vals, e_vecs = eigh(K)
  
  e_vals, e_vecs = np. flip(e_vals), np.fliplr(e_vecs) #sort in descending order

  h_star = np.column_stack([e_vecs[:, i] for i in range(num_clusters)]) 

  #h_star_normalized= normalize(h_star,norm='l2',axis=1)
  h_star_normalized= normalize(h_star,norm='l1',axis=1)

  cluster_assignment,error,last_iter,new_cluster_means=k_means(h_star_normalized,k=num_clusters,iterations=200)

  return  cluster_assignment

def k_means(data,k=4,iterations=200,se=175):


  error=[]
  np.random.seed(se)
  assignment_array,clusters=random_cluster_assignment(data,k)
  initial_cluster_means=calculate_cluster_means(clusters)
  error.append(compute_error(clusters,initial_cluster_means))
  prev_assignment= np.array(assignment_array)
  
  for i in range(iterations):
    #print(i)
    next_assignment=[]
    for k in range(len(data)):
      # prev_assignment= np.array(data_and_index)[:,1]
      closest_cluster_idx=closest_cluster(data[k],initial_cluster_means)
      next_assignment.append(closest_cluster_idx)
      updated_clusters=update_clusters_with_data_pt(data[k],closest_cluster_idx,clusters,prev_assignment[k])

      #datapoints[1]=closest_cluster_idx
    
    
    new_cluster_means=calculate_cluster_means(updated_clusters)
    initial_cluster_means=new_cluster_means
    error.append(compute_error(updated_clusters,initial_cluster_means))
    clusters=updated_clusters.copy()
    if np.sum(np.squeeze(prev_assignment) - np.squeeze(np.array(next_assignment))) !=0:
      prev_assignment= np.array(next_assignment)
      continue
    else:
      last_iter=i
      print("Last Iteration =",i)
      break
    

  #plt.figure(i)
  #plt.scatter(data_and_index[:,0][0], data[:,1], c=model.labels_.astype(float))
  return np.array(next_assignment),error,last_iter,new_cluster_means

def update_clusters_with_data_pt(Data_point,assigned_cluster, clusters,prev_assigned_cluster=0):
  #print(prev_assigned_cluster)
  if prev_assigned_cluster==0:
    clusters[assigned_cluster].append(Data_point)

  else:
    C=[]
    for i,data_point in enumerate(clusters[prev_assigned_cluster]):
    # clusters[prev_assigned_cluster].pop(Data_point)
      if np.sum(np.array(data_point)-np.array(Data_point))!=0:
        C.append(data_point)
    clusters[prev_assigned_cluster]=C
    clusters[assigned_cluster].append(Data_point)
  return clusters

def random_cluster_assignment(input_data,n_clusters=4):
  assignment_array=np.random.randint(1,n_clusters+1,len(input_data))

  clusters={}
  for i in range(1,n_clusters+1):
    clusters[i]=[]
  
  for i in range(len(input_data)):
    clusters=update_clusters_with_data_pt(input_data[i],assignment_array[i], clusters,prev_assigned_cluster=0)

  return np.array(assignment_array),clusters

def calculate_cluster_means(clusters):
  means=[]
  for i in clusters.keys():
    if len(clusters[i])!=0:
      m=np.mean(clusters[i],axis=0)
    else:
      m=np.array([0,0,0,0])
    means.append(m)
  return np.array(means)

def compute_error(clusters,means):#0,1,2,3
  err=0
  means=calculate_cluster_means(clusters)
  for i in range(len(means)):
    if len(clusters[i+1])!=0:
      err_cluster_i=np.sum((np.array(clusters[i+1]) - np.array(means[i]))**2)
      err+=err_cluster_i
  return err

def closest_cluster(data_pt,means):
  #a=np.argmin(np.sum(np.array(np.array(data_pt) - np.array(means))**2, axis=1))
  a=[]
  for mean in means:
    a.append(np.sum((np.array(data_pt) - np.array(mean))**2))

  i=np.argmin(np.array(a))
  return i+1 #cluster index

# dist_mat=pairwise_dist_matrix(X_dataset)
def plot_clusters_Using_RBF_kernel_Spectral_Kmeans(X_dataset): 
  for i in range(1,10):
    kernel=get_rbf_kernel(X_dataset,0.1*i)
    cluster_assignment=rbf_kernel_kmeans(kernel,4)
    plt.figure(i)
    sns.scatterplot(x=X_dataset[:,0],y=X_dataset[:,1],hue=cluster_assignment,palette="deep")
    plt.axis('on')
    plt.title("Spectral K-Means Clustering with rbf kernel with sigma=" +str(0.1*i))
    plt.show()

plot_clusters_Using_RBF_kernel_Spectral_Kmeans(X_dataset)